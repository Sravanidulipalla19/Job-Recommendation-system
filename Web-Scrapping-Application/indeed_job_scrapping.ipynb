{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa519928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2820939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"https://www.indeed.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3c1e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61f6e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that go through every page of inputs\n",
    "def web_scrap(url, number_of_pages):\n",
    "    json = []\n",
    "    for i in range(0, number_of_pages):\n",
    "        extension = \"\"\n",
    "        if i != 0:\n",
    "            extension = \"&start=\" + str(i*10)\n",
    "            \n",
    "        url = url + extension\n",
    "        webpg = requests.get(url)\n",
    "        soup = bs(webpg.text, \"html.parser\")\n",
    "        job_lists = soup.find_all(\"div\", {\"class\": \"job_seen_beacon\"})\n",
    "        for job in job_lists:\n",
    "            job_info = extract_job_info(job)\n",
    "            json.append(job_info)\n",
    "            \n",
    "    return json\n",
    "        \n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce59d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that extract every required information for each job in a single page\n",
    "def extract_job_info(job):\n",
    "    result_content = job.find(\"td\", {\"class\":\"resultContent\"})\n",
    "    a = result_content.find(\"a\")\n",
    "    hyperlink = a[\"href\"]\n",
    "    role_name = a.get_text()\n",
    "    job_id = a[\"id\"]\n",
    "\n",
    "    company_name = result_content.find(\"span\", {\"class\": \"companyName\"})\n",
    "    company_name = company_name.get_text()\n",
    "    location = result_content.find(\"div\", {\"class\": \"companyLocation\"})\n",
    "    location = location.get_text()\n",
    "    \n",
    "    salary_estimated = result_content.find(\"span\", {\"class\": \"estimated-salary\"})\n",
    "    if salary_estimated:\n",
    "        salary_estimated = salary_estimated.get_text()\n",
    "#     print(job_id)\n",
    "#     print(company_name)\n",
    "#     print(role_name)\n",
    "#     print(location)\n",
    "#     print(salary_estimated)\n",
    "#     print(hyperlink)\n",
    "    job_page = requests.get(prefix+hyperlink)\n",
    "    job_page = bs(job_page.text, \"html.parser\")\n",
    "#     print(job_page)\n",
    "    job_description = job_page.find(\"div\",{\"class\":\"jobsearch-jobDescriptionText\"})\n",
    "    if job_description:\n",
    "        job_description = job_description.get_text()\n",
    "#     print(job_description)\n",
    "    job_info = {\n",
    "        \"job_id\":job_id,\n",
    "        \"company_name\":company_name,\n",
    "        \"role\": role_name,\n",
    "        \"location\":location,\n",
    "        \"salary_estimated\": salary_estimated,\n",
    "        \"job_description\": job_description,\n",
    "        \"url\": prefix+hyperlink,\n",
    "    }\n",
    "    print(\" yeah! one page done!)\n",
    "    return job_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e44a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function that execute the scrapping job and store them in json format\n",
    "def main():\n",
    "    key_words = \"data\"\n",
    "    number_of_pages = 10\n",
    "    experience_level = \"ENTRY_LEVEL\"\n",
    "    job_type = \"fulltime\"\n",
    "    date_posted = 7\n",
    "    url = prefix + \"/jobs?q=\" + key_words + \"&sc=0kf%3Aexplvl%28\" + experience_level + \"%29jt%28\" + job_type +\"%29%3B&fromage=\" + str(date_posted)\n",
    "    json_data = web_scrap(url, number_of_pages)\n",
    "    with open(\"data2.json\", \"w\") as fp:\n",
    "        json.dump(json_data, fp, sort_keys=True, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0f3eae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n",
      "#################\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab3f958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c66e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e780adfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
